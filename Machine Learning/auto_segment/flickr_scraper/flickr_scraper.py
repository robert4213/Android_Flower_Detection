# Generated by Glenn Jocher (glenn.jocher@ultralytics.com) for https://github.com/ultralytics

import argparse
import os
import time
from multiprocessing import Pool

import requests
from flickrapi import FlickrAPI
import load_class

key = ''  # Flickr API key https://www.flickr.com/services/apps/create/apply
secret = ''


def download_uri(uri, dir='./'):
    with open(dir + uri.split('/')[-1], 'wb') as f:
        f.write(requests.get(uri, stream=True).content)


def get_urls(search='honeybees on flowers', n=10, download=False):
    t = time.time()
    flickr = FlickrAPI(key, secret)
    photos = flickr.walk(text=search,  # http://www.flickr.com/services/api/flickr.photos.search.html
                         extras='url_z',
                         per_page=100,
                         sort='relevance')

    if download:
        # print(search)
        folder_name = search.split(' ')
        # print(folder_name)
        folder_name = ' '.join(folder_name[:-1])
        # print(folder_name)
        
        dir = os.getcwd() + os.sep + 'images' + os.sep + folder_name + os.sep  # save directory
        if not os.path.exists(dir):
            os.makedirs(dir)

    urls = []
    for i, photo in enumerate(photos):
        if i == n:
            break

        try:
            # construct url https://www.flickr.com/services/api/misc.urls.html
            url = photo.get('url_o')  # original size
            if url is None:
                url = 'https://farm%s.staticflickr.com/%s/%s_%s_b.jpg' % \
                      (photo.get('farm'), photo.get('server'), photo.get('id'), photo.get('secret'))  # large size

            # download
            if download:
                download_uri(url, dir)

            urls.append(url)
            print('%g/%g %s' % (i, n, url))
        except:
            print('%g/%g error...' % (i, n))

    # import pandas as pd
    # urls = pd.Series(urls)
    # urls.to_csv(search + "_urls.csv")
    print('Done. (%.1fs)' % (time.time() - t) + ('\nAll images saved to %s' % dir if download else ''))


if __name__ == '__main__':
    num = 1000
    _,classes = load_class.load_class()

    p = Pool(3)

    for cl in classes:
        print('downloading {} images'.format(cl))
        p.apply_async(get_urls,(cl + ' flower',num, True))
        
    p.close()
    p.join()
    print('Finish downloading all images')